{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import datetime\n",
    "\n",
    "from time import sleep\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.offiziellecharts.de/charts/single/for-date-1515106800000\"\n",
    "\n",
    "cw = 0\n",
    "y = 2018\n",
    "\n",
    "while True:\n",
    "    rank_current = []\n",
    "    artist = []\n",
    "    title = []\n",
    "    label = []\n",
    "    incharts = []\n",
    "    peak = []\n",
    "    \n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.content, parser=\"html5lib\")\n",
    "    \n",
    "    #finding out the start and end date of the top 100 songs list\n",
    "    periodhelp = soup.find_all('strong')\n",
    "    \n",
    "    weekdates = []\n",
    "    for dt in periodhelp:\n",
    "        weekdates.append(dt.text)\n",
    "    #getting list of current rank\n",
    "    \n",
    "    rankc_help = soup.find_all('span', {'class' : 'this-week'})\n",
    "    rank_current = [int(r.text) for r in rankc_help]\n",
    "    \n",
    "    #getting list of artists\n",
    "    artist_help = soup.find_all('span', {'class' : 'info-artist'})\n",
    "    artist = [r.text for r in artist_help]\n",
    "    \n",
    "    #getting list of titles\n",
    "    title_help = soup.find_all('span', {'class' : 'info-title'})\n",
    "    title = [r.text for r in title_help]\n",
    "    \n",
    "    #getting list of labels\n",
    "    label_help = soup.find_all('span', {'class' : 'info-label'})\n",
    "    label = [r.text for r in label_help]\n",
    "    \n",
    "    #getting list of in charts information\n",
    "    \n",
    "    incharts_help = soup.find_all('span', {'class' : 'plus-data'})\n",
    "    incharts = [r.text.split()[2] for r in incharts_help if len(r.text.split()) > 2]\n",
    "    \n",
    "    #getting list of overall peak position information\n",
    "    peak_help = soup.find_all('span', {'class' : 'plus-data'})\n",
    "    peak = [r.text.split()[1] for r in peak_help if len(r.text.split()) < 3]\n",
    "    \n",
    "    dict_help = {'current_rank': rank_current,\n",
    "                 'artist': artist,\n",
    "                 'title': title,\n",
    "                 'label': label,\n",
    "                 'in_charts': incharts,\n",
    "                 'peak': peak,\n",
    "                }\n",
    "    \n",
    "    df = pd.DataFrame(dict_help)\n",
    "    df['weekbegin'] = datetime.datetime.strptime(weekdates[0], \"%d.%m.%Y\")\n",
    "    df['weekend'] = datetime.datetime.strptime(weekdates[1], \"%d.%m.%Y\")\n",
    "    df['year'] = datetime.datetime.strptime(weekdates[0], \"%d.%m.%Y\").year\n",
    "    df['month'] = datetime.datetime.strptime(weekdates[0], \"%d.%m.%Y\").month\n",
    "    \n",
    "    if int(datetime.datetime.strptime(weekdates[0], \"%d.%m.%Y\").year) == y:\n",
    "        cw += 1\n",
    "        savename_pickle = \"../pickle/charts_\" + str(y) + \"_\" + str(cw) + \".pkl\"\n",
    "        savename_csv = \"../csv/charts_\" + str(y) + \"_\" + str(cw) + \".csv\"\n",
    "        df.to_pickle(savename_pickle)\n",
    "        df.to_csv(savename_csv, index=False)\n",
    "        \n",
    "    elif int(datetime.datetime.strptime(weekdates[0], \"%d.%m.%Y\").year) > y:\n",
    "        y = int(datetime.datetime.strptime(weekdates[0], \"%d.%m.%Y\").year)\n",
    "        cw = 1\n",
    "        savename_pickle = \"../pickle/charts_\" + str(y) + \"_\" + str(cw) + \".pkl\"\n",
    "        savename_csv = \"../csv/charts_\" + str(y) + \"_\" + str(cw) + \".csv\"\n",
    "        df.to_pickle(savename_pickle)\n",
    "        df.to_csv(savename_csv, index=False)\n",
    "    \n",
    "    if len(soup.find_all('a', {'class' : 'next-link btn btn-default btn-sm'})) > 0:\n",
    "        url = \"https://www.offiziellecharts.de\" + str([a['href'] for a in soup.find_all('a', {'class' : 'next-link btn btn-default btn-sm'})][0]) + \"/\"\n",
    "        #Nap time!\n",
    "        wait_time = randint(1,5)\n",
    "        sleep(wait_time)\n",
    "        continue\n",
    "    \n",
    "    elif (len(soup.find_all('a', {'class' : 'next-link btn btn-default btn-sm'})) <= 0):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
